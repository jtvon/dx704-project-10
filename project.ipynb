{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 10 Project\n",
        "\n",
        "In this project, you will implement document search within a question and answer database and assess its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B2Ff6lisqH"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 10 Materials](https://github.com/bu-cds-dx704/dx704-project-10).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEezzKGSdyXB"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQhkdHNFbwLp"
      },
      "source": [
        "## Part 1: Download the SQuAD-explorer Data Set\n",
        "\n",
        "You may use the code provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KDN4uTycILU",
        "outputId": "263d0284-de7d-493e-c40f-92161d739ac0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SQuAD-explorer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rajpurkar/SQuAD-explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W7Cgmz-lVmBF"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kXc87YHZVsOz"
      },
      "outputs": [],
      "source": [
        "with open(\"SQuAD-explorer/dataset/train-v1.1.json\") as fp:\n",
        "    train_data = json.load(fp, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYKgEa3V149",
        "outputId": "d512a1ae-7e36-4675-c3b9-05ebea9bf9df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJrdzIqwV3FK",
        "outputId": "78415ac7-f68a-4179-cc19-6ccd18c00b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data', 'version']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbru7Z_UV74r",
        "outputId": "5c90d6d6-e0db-459e-fc99-8c59e0d7ee54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLq8Xo_V-Ji",
        "outputId": "214682af-3013-4c9c-a344-1953dd6e7120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIaSECnAWBv7",
        "outputId": "d9e182f7-22c8-4f9b-c756-adacde1112ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4bVs4bWJ7l",
        "outputId": "9dc04b5a-0943-4cb2-d78b-c137545a35ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uIwF0bTeWMEC",
        "outputId": "357ae956-3930-418f-e822-62de93d2fcb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YopAkB-WOTW",
        "outputId": "e2767d66-e39b-40f4-bd42-47a40c9240ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"][0][\"paragraphs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bm3BAIqWRCT",
        "outputId": "da233573-f62c-46ee-9384-16fd6a110ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'qas': [{'answers': [{'answer_start': 515,\n",
              "     'text': 'Saint Bernadette Soubirous'}],\n",
              "   'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              "   'id': '5733be284776f41900661182'},\n",
              "  {'answers': [{'answer_start': 188, 'text': 'a copper statue of Christ'}],\n",
              "   'question': 'What is in front of the Notre Dame Main Building?',\n",
              "   'id': '5733be284776f4190066117f'},\n",
              "  {'answers': [{'answer_start': 279, 'text': 'the Main Building'}],\n",
              "   'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              "   'id': '5733be284776f41900661180'},\n",
              "  {'answers': [{'answer_start': 381,\n",
              "     'text': 'a Marian place of prayer and reflection'}],\n",
              "   'question': 'What is the Grotto at Notre Dame?',\n",
              "   'id': '5733be284776f41900661181'},\n",
              "  {'answers': [{'answer_start': 92,\n",
              "     'text': 'a golden statue of the Virgin Mary'}],\n",
              "   'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "   'id': '5733be284776f4190066117e'}]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"paragraphs\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7RL5JTWraU",
        "outputId": "2a09c434-6eb4-4bba-9a60-d323136cfbfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18896"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(len(doc[\"paragraphs\"]) for doc in train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 2: Restructure JSON Data for Processing\n",
        "\n",
        "Parse the file \"SQuAD-explorer/dataset/train-v1.1.json\" above to produce a file \"parsed.tsv\" with columns document_title, paragraph_index, and paragraph_context.\n",
        "The paragraph_index column should be zero-indexed, so zero for the first paragraph of each document.\n",
        "Use pandas `to_csv` method to write the file since there are many quotes and other issues to handle otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('pretty_json.json', 'w') as f:\n",
        "    json.dump(train_data, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QJHSCtWWaLAG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created parsed.tsv with 18896 rows.\n",
            "Sample of the first couple rows:\n",
            "             document_title  paragraph_index  \\\n",
            "0  University_of_Notre_Dame                0   \n",
            "1  University_of_Notre_Dame                1   \n",
            "2  University_of_Notre_Dame                2   \n",
            "3  University_of_Notre_Dame                3   \n",
            "4  University_of_Notre_Dame                4   \n",
            "\n",
            "                                   paragraph_context  \n",
            "0  Architecturally, the school has a Catholic cha...  \n",
            "1  As at most other universities, Notre Dame's st...  \n",
            "2  The university is the major seat of the Congre...  \n",
            "3  The College of Engineering was established in ...  \n",
            "4  All of Notre Dame's undergraduate students are...  \n"
          ]
        }
      ],
      "source": [
        "# Parse the contents of train_data to create a new file called \"parsed.tsv\"\n",
        "import pandas as pd\n",
        "\n",
        "parsed_file = []\n",
        "\n",
        "# loop through josn to find all titles\n",
        "for doc in train_data['data']:\n",
        "    title = doc['title']\n",
        "    for idx, paragraph in enumerate(doc['paragraphs']):\n",
        "        context = paragraph['context']\n",
        "        parsed_file.append({\n",
        "            'document_title': title,\n",
        "            'paragraph_index': idx,\n",
        "            'paragraph_context': context\n",
        "        })\n",
        "\n",
        "# convert to dataframe\n",
        "df = pd.DataFrame(parsed_file)\n",
        "df.to_csv('submission/parsed.tsv', sep='\\t', index=False)\n",
        "\n",
        "# print preview of the data\n",
        "print(f\"Created parsed.tsv with {len(df)} rows.\")\n",
        "print(\"Sample of the first couple rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9VpBX7aNLP"
      },
      "source": [
        "Submit \"parsed.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7Sr3TdcTqr"
      },
      "source": [
        "## Part 3: Prepare Suitable Paragraph Vectors for Document Search\n",
        "\n",
        "Design and implement paragraph vectors based on their text with length 1024.\n",
        "Note that this will be much smaller than the number of distinct words in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkun5bA1J6c"
      },
      "source": [
        "Hint: you can base your vectors on any techniques covered in this module so far.\n",
        "Beware that they will be automatically assessed (along with the question vectors of part 4) to make sure they retain useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v978AkFmdnLD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paragraph vectors shape: (18896, 1024)\n",
            "Vocabulary size: 1024\n",
            "Number of features: 1024\n"
          ]
        }
      ],
      "source": [
        "# Design paragraph vectors based on the text length 1024\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1024)\n",
        "X = vectorizer.fit_transform(df['paragraph_context'])\n",
        "\n",
        "print(f\"Paragraph vectors shape: {X.shape}\")\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZRTxludpHC"
      },
      "source": [
        "Save your paragraph vectors in a file \"paragraph-vectors.tsv.gz\" with columns document_title, paragraph_index, and paragraph_vector_json where paragraph_vector_json is a JSON encoded list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGE7ooGVckTC"
      },
      "source": [
        "Hint: don't forget the \".gz\" extension indicating gzip compression.\n",
        "The Pandas `.to_csv` method will automatically add the compression if you save data with a filename ending in \".gz\", so you just need to pass it the right filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nNvDMTE1edGm"
      },
      "outputs": [],
      "source": [
        "# Save the vectors in a new file\n",
        "df_X = pd.DataFrame(X.toarray())\n",
        "df_vectors = pd.DataFrame({'document_title': df['document_title'], 'paragraph_index': df['paragraph_index'], 'paragraph_vector_json': df_X.values.tolist()})\n",
        "df_vectors.to_csv('submission/paragraph-vectors.tsv.gz', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71KxgBp-eeqm"
      },
      "source": [
        "Submit \"paragraph-vectors.tsv.gz\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPL_MR_GeSa1"
      },
      "source": [
        "## Part 4: Encode Question Vectors with the Same Design\n",
        "\n",
        "Read the questions in \"questions.tsv\" and encode them in the same way that you encoded the paragraph vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "75F95fJjpZ3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question vectors shape: (100, 1024)\n",
            "Paragraph vectors shape: (18896, 1024)\n",
            "Vectors have same number of features: True\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What was the goal of the abuse of region project?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>How many satellites in the Beidou-1 constellat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>When did Beyoncé  receive ten nominations for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>With which goddess did Sulla, Pompey, and Juli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>What area is considered to have a desert clima...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id                                           question\n",
              "0            1  What was the goal of the abuse of region project?\n",
              "1            4  How many satellites in the Beidou-1 constellat...\n",
              "2            7  When did Beyoncé  receive ten nominations for ...\n",
              "3           10  With which goddess did Sulla, Pompey, and Juli...\n",
              "4           13  What area is considered to have a desert clima..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the questions file and encode using the SAME vectorizer from paragraphs\n",
        "df_questions = pd.read_csv('questions.tsv', sep='\\t')\n",
        "\n",
        "# Use transform() NOT fit_transform() - we want to use the same vocabulary as paragraphs\n",
        "questions_json = vectorizer.transform(df_questions['question'])\n",
        "\n",
        "print(f\"Question vectors shape: {questions_json.shape}\")\n",
        "print(f\"Paragraph vectors shape: {X.shape}\")\n",
        "print(f\"Vectors have same number of features: {questions_json.shape[1] == X.shape[1]}\")\n",
        "df_questions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5j32O5pb03"
      },
      "source": [
        "Save your question vectors in \"question-vectors.tsv\" with columns question_id and question_vector_json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oLyvhIcYpr06"
      },
      "outputs": [],
      "source": [
        "# Save the question vectors in a new file\n",
        "df_ques_vec = pd.DataFrame({'question_id': df_questions['question_id'], 'question_vector_json': questions_json.toarray().tolist()})\n",
        "df_ques_vec.to_csv('submission/question-vectors.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmcWnJUptZN"
      },
      "source": [
        "Submit \"question-vectors.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRDyTUxcvCx"
      },
      "source": [
        "## Part 5: Match Questions to Paragraphs using Nearest Neighbors\n",
        "\n",
        "Match your question vectors to paragraph vectors and identify the top 5 paragraph vectors for each question using nearest neighbors.\n",
        "Specifically, use the Euclidean distance between the vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dJlB2SsMqf1F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paragraph vectors shape: (18896, 1024)\n",
            "Question vectors shape: (100, 1024)\n",
            "\n",
            "Sample of the nearest neighbors predictions:\n",
            "Total questions: 100\n",
            "Total paragraphs: 18896\n",
            "\n",
            "First 5 questions with their top 5 paragraph matches:\n",
            "\n",
            "Question ID: 1\n",
            "  Top 5 Nearest Paragraph Indices: [17565  1682 15050  8514 13052]\n",
            "  Distances: [0.96707749 1.06718706 1.06821745 1.08058451 1.09104342]\n",
            "  Document Titles: ['Tuvalu', 'Genome', 'Rajasthan', 'Bill_%26_Melinda_Gates_Foundation', 'Tibet']\n",
            "\n",
            "Question ID: 4\n",
            "  Top 5 Nearest Paragraph Indices: [ 1402  8005 15809 13021  4128]\n",
            "  Distances: [0.97116657 1.01456967 1.08084652 1.08354636 1.11257042]\n",
            "  Document Titles: ['Dog', 'Multiracial_American', 'The_Blitz', 'Rule_of_law', 'Classical_music']\n",
            "\n",
            "Question ID: 7\n",
            "  Top 5 Nearest Paragraph Indices: [ 1166 15803  1267  6242  5036]\n",
            "  Distances: [1.09428625 1.1887239  1.19491097 1.20351572 1.20422867]\n",
            "  Document Titles: ['Buddhism', 'The_Blitz', 'American_Idol', 'Gymnastics', 'High-definition_television']\n",
            "\n",
            "Question ID: 10\n",
            "  Top 5 Nearest Paragraph Indices: [15181 12875  5378   342  1929]\n",
            "  Distances: [1.07339442 1.11412047 1.14841759 1.15033272 1.15509923]\n",
            "  Document Titles: ['Education', 'Unicode', 'Computer', 'Sino-Tibetan_relations_during_the_Ming_dynasty', 'Symbiosis']\n",
            "\n",
            "Question ID: 13\n",
            "  Top 5 Nearest Paragraph Indices: [11021 17067 13903   951  9255]\n",
            "  Distances: [1.002127   1.12970865 1.14379435 1.15929619 1.15931762]\n",
            "  Document Titles: ['Mali', 'San_Diego', 'Alaska', 'Portugal', 'Southeast_Asia']\n",
            "\n",
            "Sample of the nearest neighbors predictions:\n",
            "Total questions: 100\n",
            "Total paragraphs: 18896\n",
            "\n",
            "First 5 questions with their top 5 paragraph matches:\n",
            "\n",
            "Question ID: 1\n",
            "  Top 5 Nearest Paragraph Indices: [17565  1682 15050  8514 13052]\n",
            "  Distances: [0.96707749 1.06718706 1.06821745 1.08058451 1.09104342]\n",
            "  Document Titles: ['Tuvalu', 'Genome', 'Rajasthan', 'Bill_%26_Melinda_Gates_Foundation', 'Tibet']\n",
            "\n",
            "Question ID: 4\n",
            "  Top 5 Nearest Paragraph Indices: [ 1402  8005 15809 13021  4128]\n",
            "  Distances: [0.97116657 1.01456967 1.08084652 1.08354636 1.11257042]\n",
            "  Document Titles: ['Dog', 'Multiracial_American', 'The_Blitz', 'Rule_of_law', 'Classical_music']\n",
            "\n",
            "Question ID: 7\n",
            "  Top 5 Nearest Paragraph Indices: [ 1166 15803  1267  6242  5036]\n",
            "  Distances: [1.09428625 1.1887239  1.19491097 1.20351572 1.20422867]\n",
            "  Document Titles: ['Buddhism', 'The_Blitz', 'American_Idol', 'Gymnastics', 'High-definition_television']\n",
            "\n",
            "Question ID: 10\n",
            "  Top 5 Nearest Paragraph Indices: [15181 12875  5378   342  1929]\n",
            "  Distances: [1.07339442 1.11412047 1.14841759 1.15033272 1.15509923]\n",
            "  Document Titles: ['Education', 'Unicode', 'Computer', 'Sino-Tibetan_relations_during_the_Ming_dynasty', 'Symbiosis']\n",
            "\n",
            "Question ID: 13\n",
            "  Top 5 Nearest Paragraph Indices: [11021 17067 13903   951  9255]\n",
            "  Distances: [1.002127   1.12970865 1.14379435 1.15929619 1.15931762]\n",
            "  Document Titles: ['Mali', 'San_Diego', 'Alaska', 'Portugal', 'Southeast_Asia']\n"
          ]
        }
      ],
      "source": [
        "# Match question vectors to paragraph vectors using nearest neighbors\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "# Convert vector lists to numpy arrays\n",
        "paragraph_vectors = np.array(df_vectors['paragraph_vector_json'].tolist())\n",
        "question_vectors = np.array(df_ques_vec['question_vector_json'].tolist())\n",
        "\n",
        "print(f\"Paragraph vectors shape: {paragraph_vectors.shape}\")\n",
        "print(f\"Question vectors shape: {question_vectors.shape}\")\n",
        "\n",
        "# Check if dimensions match\n",
        "if paragraph_vectors.shape[1] != question_vectors.shape[1]:\n",
        "    raise ValueError(f\"Dimension mismatch! Paragraphs have {paragraph_vectors.shape[1]} features, \"\n",
        "                     f\"but questions have {question_vectors.shape[1]} features. \"\n",
        "                     f\"Make sure to re-run Part 3 before Part 4!\")\n",
        "\n",
        "# Initialize and fit the model on PARAGRAPH vectors (the search space)\n",
        "model = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
        "model.fit(paragraph_vectors)\n",
        "\n",
        "# Find nearest paragraphs for each QUESTION vector\n",
        "distances, indices = model.kneighbors(question_vectors)\n",
        "\n",
        "# Print preview of the predictions\n",
        "print(\"\\nSample of the nearest neighbors predictions:\")\n",
        "print(f\"Total questions: {len(question_vectors)}\")\n",
        "print(f\"Total paragraphs: {len(paragraph_vectors)}\")\n",
        "print(\"\\nFirst 5 questions with their top 5 paragraph matches:\")\n",
        "for i in range(min(5, len(df_ques_vec))):\n",
        "    print(f\"\\nQuestion ID: {df_ques_vec['question_id'].iloc[i]}\")\n",
        "    print(f\"  Top 5 Nearest Paragraph Indices: {indices[i]}\")\n",
        "    print(f\"  Distances: {distances[i]}\")\n",
        "    print(f\"  Document Titles: {[df_vectors['document_title'].iloc[idx] for idx in indices[i]]}\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvjW3nP-qkSk"
      },
      "source": [
        "Save your top matches in a file \"question-matches.tsv\" with columns question_id, question_rank, document_title, and paragraph_index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "heaNwWMlrAwv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created question-matches.tsv with 500 rows\n",
            "Expected: 100 questions × 5 matches = 500 rows\n",
            "\n",
            "Sample of first question's matches:\n",
            "   question_id  question_rank                     document_title  \\\n",
            "0            1              0                             Tuvalu   \n",
            "1            1              1                             Genome   \n",
            "2            1              2                          Rajasthan   \n",
            "3            1              3  Bill_%26_Melinda_Gates_Foundation   \n",
            "4            1              4                              Tibet   \n",
            "\n",
            "   paragraph_index  \n",
            "0               49  \n",
            "1                8  \n",
            "2                9  \n",
            "3                6  \n",
            "4               10  \n"
          ]
        }
      ],
      "source": [
        "# Create the question matches file\n",
        "matches = []\n",
        "\n",
        "for q_idx, question_id in enumerate(df_ques_vec['question_id']):\n",
        "    # Get the 5 nearest paragraph indices for this question\n",
        "    for rank, para_idx in enumerate(indices[q_idx]):\n",
        "        matches.append({\n",
        "            'question_id': question_id,\n",
        "            'question_rank': rank,  # 0-4 for top 5 matches\n",
        "            'document_title': df_vectors['document_title'].iloc[para_idx],\n",
        "            'paragraph_index': df_vectors['paragraph_index'].iloc[para_idx]\n",
        "        })\n",
        "\n",
        "# Create DataFrame and save\n",
        "df_matches = pd.DataFrame(matches)\n",
        "df_matches.to_csv('submission/question-matches.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Created question-matches.tsv with {len(df_matches)} rows\")\n",
        "print(f\"Expected: {len(df_ques_vec)} questions × 5 matches = {len(df_ques_vec) * 5} rows\")\n",
        "print(\"\\nSample of first question's matches:\")\n",
        "print(df_matches[df_matches['question_id'] == df_ques_vec['question_id'].iloc[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0m-ogJjrCK8"
      },
      "source": [
        "Submit \"question-matches.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftG5ez0tsyy"
      },
      "source": [
        "## Part 6: Spot Check Question and Paragraph Matches\n",
        "\n",
        "Review the paragraphs matched to the first 5 questions (sorted by question_id ascending).\n",
        "Which paragraph was the worst match for each question?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "QUESTION ID: 1\n",
            "Question: What was the goal of the abuse of region project?\n",
            "================================================================================\n",
            "\n",
            "--- RANK 1 ---\n",
            "Document: Tuvalu\n",
            "Paragraph Index: 49\n",
            "\n",
            "Paragraph Text:\n",
            "The eastern shoreline of Funafuti Lagoon was modified during World War II when\n",
            "the airfield (what is now Funafuti International Airport) was constructed. The\n",
            "coral base of the atoll was used as fill to create the runway. The resulting\n",
            "borrow pits impacted the fresh-water aquifer. In the low areas of Funafuti the\n",
            "sea water can be seen bubbling up through the porous coral rock to form pools\n",
            "with each high tide. Since 1994 a project has been in development to assess the\n",
            "environmental impact of transporting sand from the lagoon to fill all the borrow\n",
            "pits and low-lying areas on Fongafale. In 2014 the Tuvalu Borrow Pits\n",
            "Remediation (BPR) project was approved in order to fill 10 borrow pits, leaving\n",
            "Tafua Pond, which is a natural pond. The New Zealand Government funded the BPR\n",
            "project. The project was carried out in 2015 with 365,000 sqm of sand being\n",
            "dredged from the lagoon to fill the holes and improve living conditions on the\n",
            "island. This project increase the usable land space on Fongafale by eight per\n",
            "cent.\n",
            "\n",
            "\n",
            "--- RANK 2 ---\n",
            "Document: Genome\n",
            "Paragraph Index: 8\n",
            "\n",
            "Paragraph Text:\n",
            "Whereas a genome sequence lists the order of every DNA base in a genome, a\n",
            "genome map identifies the landmarks. A genome map is less detailed than a genome\n",
            "sequence and aids in navigating around the genome. The Human Genome Project was\n",
            "organized to map and to sequence the human genome. A fundamental step in the\n",
            "project was the release of a detailed genomic map by Jean Weissenbach and his\n",
            "team at the Genoscope in Paris.\n",
            "\n",
            "\n",
            "--- RANK 3 ---\n",
            "Document: Rajasthan\n",
            "Paragraph Index: 9\n",
            "\n",
            "Paragraph Text:\n",
            "The Aravalli Range and the lands to the east and southeast of the range are\n",
            "generally more fertile and better watered. This region is home to the\n",
            "Kathiarbar-Gir dry deciduous forests ecoregion, with tropical dry broadleaf\n",
            "forests that include teak, Acacia, and other trees. The hilly Vagad region, home\n",
            "to the cities of Dungarpur and Banswara lies in southernmost Rajasthan, on the\n",
            "border with Gujarat and Madhya Pradesh. With the exception of Mount Abu, Vagad\n",
            "is the wettest region in Rajasthan, and the most heavily forested. North of\n",
            "Vagad lies the Mewar region, home to the cities of Udaipur and Chittaurgarh. The\n",
            "Hadoti region lies to the southeast, on the border with Madhya Pradesh. North of\n",
            "Hadoti and Mewar lies the Dhundhar region, home to the state capital of Jaipur.\n",
            "Mewat, the easternmost region of Rajasthan, borders Haryana and Uttar Pradesh.\n",
            "Eastern and southeastern Rajasthan is drained by the Banas and Chambal rivers,\n",
            "tributaries of the Ganges.\n",
            "\n",
            "\n",
            "--- RANK 4 ---\n",
            "Document: Bill_%26_Melinda_Gates_Foundation\n",
            "Paragraph Index: 6\n",
            "\n",
            "Paragraph Text:\n",
            "The IJM used the grant money to found \"Project Lantern\" and established an\n",
            "office in the Philippines city of Cebu. In 2010 the results of the project were\n",
            "published, in which the IJM stated that Project Lantern had led to \"an increase\n",
            "in law enforcement activity in sex trafficking cases, an increase in commitment\n",
            "to resolving sex trafficking cases among law enforcement officers trained\n",
            "through the project, and an increase in services – like shelter, counseling and\n",
            "career training – provided to trafficking survivors\". At the time that the\n",
            "results were released, the IJM was exploring opportunities to replicate the\n",
            "model in other regions.\n",
            "\n",
            "\n",
            "--- RANK 5 ---\n",
            "Document: Tibet\n",
            "Paragraph Index: 10\n",
            "\n",
            "Paragraph Text:\n",
            "The earliest Tibetan historical texts identify the Zhang Zhung culture as a\n",
            "people who migrated from the Amdo region into what is now the region of Guge in\n",
            "western Tibet. Zhang Zhung is considered to be the original home of the Bön\n",
            "religion. By the 1st century BCE, a neighboring kingdom arose in the Yarlung\n",
            "valley, and the Yarlung king, Drigum Tsenpo, attempted to remove the influence\n",
            "of the Zhang Zhung by expelling the Zhang's Bön priests from Yarlung. He was\n",
            "assassinated and Zhang Zhung continued its dominance of the region until it was\n",
            "annexed by Songtsen Gampo in the 7th century. Prior to Songtsän Gampo, the kings\n",
            "of Tibet were more mythological than factual, and there is insufficient evidence\n",
            "of their existence.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 4\n",
            "Question: How many satellites in the Beidou-1 constellation?\n",
            "================================================================================\n",
            "\n",
            "--- RANK 1 ---\n",
            "Document: Dog\n",
            "Paragraph Index: 27\n",
            "\n",
            "Paragraph Text:\n",
            "Dog communication is about how dogs \"speak\" to each other, how they understand\n",
            "messages that humans send to them, and how humans can translate the ideas that\n",
            "dogs are trying to transmit.:xii These communication behaviors include eye gaze,\n",
            "facial expression, vocalization, body posture (including movements of bodies and\n",
            "limbs) and gustatory communication (scents, pheromones and taste). Humans\n",
            "communicate with dogs by using vocalization, hand signals and body posture.\n",
            "\n",
            "\n",
            "--- RANK 2 ---\n",
            "Document: Multiracial_American\n",
            "Paragraph Index: 17\n",
            "\n",
            "Paragraph Text:\n",
            "Prior to the one-drop rule, different states had different laws regarding color.\n",
            "More importantly, social acceptance often played a bigger role in how a person\n",
            "was perceived and how identity was construed than any law. In frontier areas,\n",
            "there were fewer questions about origins. The community looked at how people\n",
            "performed, whether they served in the militia and voted, which were the\n",
            "responsibilities and signs of free citizens. When questions about racial\n",
            "identity arose because of inheritance issues, for instance, litigation outcomes\n",
            "often were based on how people were accepted by neighbors.\n",
            "\n",
            "\n",
            "--- RANK 3 ---\n",
            "Document: The_Blitz\n",
            "Paragraph Index: 10\n",
            "\n",
            "Paragraph Text:\n",
            "The deliberate separation of the Luftwaffe from the rest of the military\n",
            "structure encouraged the emergence of a major \"communications gap\" between\n",
            "Hitler and the Luftwaffe, which other factors helped to exacerbate. For one\n",
            "thing, Göring's fear of Hitler led him to falsify or misrepresent what\n",
            "information was available in the direction of an uncritical and over-optimistic\n",
            "interpretation of air strength. When Göring decided against continuing Wever's\n",
            "original heavy bomber programme in 1937, the Reichsmarschall's own explanation\n",
            "was that Hitler wanted to know only how many bombers there were, not how many\n",
            "engines each had. In July 1939, Göring arranged a display of the Luftwaffe's\n",
            "most advanced equipment at Rechlin, to give the impression the air force was\n",
            "more prepared for a strategic air war than was actually the case.\n",
            "\n",
            "\n",
            "--- RANK 4 ---\n",
            "Document: Rule_of_law\n",
            "Paragraph Index: 3\n",
            "\n",
            "Paragraph Text:\n",
            "There has recently been an effort to reevaluate the influence of the Bible on\n",
            "Western constitutional law. In the Old Testament, there was some language in\n",
            "Deuteronomy imposing restrictions on the Jewish king, regarding such things as\n",
            "how many wives he could have, and how many horses he could own for his personal\n",
            "use. According to Professor Bernard M. Levinson, \"This legislation was so\n",
            "utopian in its own time that it seems never to have been implemented....\" The\n",
            "Deuteronomic social vision may have influenced opponents of the divine right of\n",
            "kings, including Bishop John Ponet in sixteenth-century England.\n",
            "\n",
            "\n",
            "--- RANK 5 ---\n",
            "Document: Classical_music\n",
            "Paragraph Index: 5\n",
            "\n",
            "Paragraph Text:\n",
            "That said, the score does not provide complete and exact instructions on how to\n",
            "perform a historical work. Even if the tempo is written with an Italian\n",
            "instruction (e.g., Allegro), we do not know exactly how fast the piece should be\n",
            "played. As well, in the Baroque era, many works that were designed for basso\n",
            "continuo accompaniment do not specify which instruments should play the\n",
            "accompaniment or exactly how the chordal instrument (harpsichord, lute, etc.)\n",
            "should play the chords, which are not notated in the part (only a figured bass\n",
            "symbol beneath the bass part is used to guide the chord-playing performer). The\n",
            "performer and/or the conductor have a range of options for musical expression\n",
            "and interpretation of a scored piece, including the phrasing of melodies, the\n",
            "time taken during fermatas (held notes) or pauses, and the use (or choice not to\n",
            "use) of effects such as vibrato or glissando (these effects are possible on\n",
            "various stringed, brass and woodwind instruments and with the human voice).\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 7\n",
            "Question: When did Beyoncé  receive ten nominations for the Grammy Awards?\n",
            "================================================================================\n",
            "\n",
            "--- RANK 1 ---\n",
            "Document: Buddhism\n",
            "Paragraph Index: 67\n",
            "\n",
            "Paragraph Text:\n",
            "The complete list of ten precepts may be observed by laypeople for short\n",
            "periods. For the complete list, the seventh precept is partitioned into two, and\n",
            "a tenth added:\n",
            "\n",
            "\n",
            "--- RANK 2 ---\n",
            "Document: The_Blitz\n",
            "Paragraph Index: 4\n",
            "\n",
            "Paragraph Text:\n",
            "Within the Luftwaffe, there was a more muted view of strategic bombing. The OKL\n",
            "did not oppose the strategic bombardment of enemy industries and or cities, and\n",
            "believed it could greatly affect the balance of power on the battlefield in\n",
            "Germany's favour by disrupting production and damaging civilian morale, but they\n",
            "did not believe that air power alone could be decisive. Contrary to popular\n",
            "belief, the Luftwaffe did not have a systematic policy of what became known as\n",
            "\"terror bombing\". Evidence suggests that the Luftwaffe did not adopt an official\n",
            "bombing policy in which civilians became the primary target until 1942.\n",
            "\n",
            "\n",
            "--- RANK 3 ---\n",
            "Document: American_Idol\n",
            "Paragraph Index: 19\n",
            "\n",
            "Paragraph Text:\n",
            "The finals are broadcast in prime time from CBS Television City in Los Angeles,\n",
            "in front of a live studio audience. The finals lasted eight weeks in season one,\n",
            "eleven weeks in subsequent seasons until seasons ten and eleven which lasted\n",
            "twelve weeks except for season twelve, which lasted ten weeks, and season\n",
            "thirteen, which lasted for thirteen weeks. Each finalist performs songs based on\n",
            "a weekly theme which may be a musical genre such as Motown, disco, or big band,\n",
            "songs by artists such as Michael Jackson, Elvis Presley or The Beatles, or more\n",
            "general themes such as Billboard Number 1 hits or songs from the contestant's\n",
            "year of birth. Contestants usually work with a celebrity mentor related to the\n",
            "theme. In season ten, Jimmy Iovine was brought in as a mentor for the season.\n",
            "Initially the contestants sing one song each week, but this is increased to two\n",
            "songs from top four or five onwards, then three songs for the top two or three.\n",
            "\n",
            "\n",
            "--- RANK 4 ---\n",
            "Document: Gymnastics\n",
            "Paragraph Index: 12\n",
            "\n",
            "Paragraph Text:\n",
            "Individual routines in trampolining involve a build-up phase during which the\n",
            "gymnast jumps repeatedly to achieve height, followed by a sequence of ten\n",
            "bounces without pause during which the gymnast performs a sequence of aerial\n",
            "skills. Routines are marked out of a maximum score of 10 points. Additional\n",
            "points (with no maximum at the highest levels of competition) can be earned\n",
            "depending on the difficulty of the moves and the length of time taken to\n",
            "complete the ten skills which is an indication of the average height of the\n",
            "jumps. In high level competitions, there are two preliminary routines, one which\n",
            "has only two moves scored for difficulty and one where the athlete is free to\n",
            "perform any routine. This is followed by a final routine which is optional. Some\n",
            "competitions restart the score from zero for the finals, other add the final\n",
            "score to the preliminary results.\n",
            "\n",
            "\n",
            "--- RANK 5 ---\n",
            "Document: High-definition_television\n",
            "Paragraph Index: 11\n",
            "\n",
            "Paragraph Text:\n",
            "The limited standardization of analog HDTV in the 1990s did not lead to global\n",
            "HDTV adoption as technical and economic constraints at the time did not permit\n",
            "HDTV to use bandwidths greater than normal television.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 10\n",
            "Question: With which goddess did Sulla, Pompey, and Julius Caesar all claim a special relationship?\n",
            "================================================================================\n",
            "\n",
            "--- RANK 1 ---\n",
            "Document: Education\n",
            "Paragraph Index: 26\n",
            "\n",
            "Paragraph Text:\n",
            "Educational psychology can in part be understood through its relationship with\n",
            "other disciplines. It is informed primarily by psychology, bearing a\n",
            "relationship to that discipline analogous to the relationship between medicine\n",
            "and biology. Educational psychology in turn informs a wide range of specialties\n",
            "within educational studies, including instructional design, educational\n",
            "technology, curriculum development, organizational learning, special education\n",
            "and classroom management. Educational psychology both draws from and contributes\n",
            "to cognitive science and the learning sciences. In universities, departments of\n",
            "educational psychology are usually housed within faculties of education,\n",
            "possibly accounting for the lack of representation of educational psychology\n",
            "content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).\n",
            "\n",
            "\n",
            "--- RANK 2 ---\n",
            "Document: Unicode\n",
            "Paragraph Index: 18\n",
            "\n",
            "Paragraph Text:\n",
            "Many scripts, including Arabic and Devanagari, have special orthographic rules\n",
            "that require certain combinations of letterforms to be combined into special\n",
            "ligature forms. The rules governing ligature formation can be quite complex,\n",
            "requiring special script-shaping technologies such as ACE (Arabic Calligraphic\n",
            "Engine by DecoType in the 1980s and used to generate all the Arabic examples in\n",
            "the printed editions of the Unicode Standard), which became the proof of concept\n",
            "for OpenType (by Adobe and Microsoft), Graphite (by SIL International), or AAT\n",
            "(by Apple).\n",
            "\n",
            "\n",
            "--- RANK 3 ---\n",
            "Document: Computer\n",
            "Paragraph Index: 50\n",
            "\n",
            "Paragraph Text:\n",
            "A key component common to all CPUs is the program counter, a special memory cell\n",
            "(a register) that keeps track of which location in memory the next instruction\n",
            "is to be read from.\n",
            "\n",
            "\n",
            "--- RANK 4 ---\n",
            "Document: Sino-Tibetan_relations_during_the_Ming_dynasty\n",
            "Paragraph Index: 43\n",
            "\n",
            "Paragraph Text:\n",
            "With the example of the Ming court's relationship with the fifth Karmapa and\n",
            "other Tibetan leaders, Norbu states that Chinese Communist historians have\n",
            "failed to realize the significance of the religious aspect of the Ming-Tibetan\n",
            "relationship. He writes that the meetings of lamas with the Emperor of China\n",
            "were exchanges of tribute between \"the patron and the priest\" and were not\n",
            "merely instances of a political subordinate paying tribute to a superior. He\n",
            "also notes that the items of tribute were Buddhist artifacts which symbolized\n",
            "\"the religious nature of the relationship.\" Josef Kolmaš writes that the Ming\n",
            "dynasty did not exercise any direct political control over Tibet, content with\n",
            "their tribute relations that were \"almost entirely of a religious character.\"\n",
            "Patricia Ann Berger writes that the Yongle Emperor's courting and granting of\n",
            "titles to lamas was his attempt to \"resurrect the relationship between China and\n",
            "Tibet established earlier by the Yuan dynastic founder Khubilai Khan and his\n",
            "guru Phagpa.\" She also writes that the later Qing emperors and their Mongol\n",
            "associates viewed the Yongle Emperor's relationship with Tibet as \"part of a\n",
            "chain of reincarnation that saw this Han Chinese emperor as yet another\n",
            "emanation of Manjusri.\"\n",
            "\n",
            "\n",
            "--- RANK 5 ---\n",
            "Document: Symbiosis\n",
            "Paragraph Index: 8\n",
            "\n",
            "Paragraph Text:\n",
            "An example of mutual symbiosis is the relationship between the ocellaris\n",
            "clownfish that dwell among the tentacles of Ritteri sea anemones. The\n",
            "territorial fish protects the anemone from anemone-eating fish, and in turn the\n",
            "stinging tentacles of the anemone protect the clownfish from its predators. A\n",
            "special mucus on the clownfish protects it from the stinging tentacles.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 13\n",
            "Question: What area is considered to have a desert climate despite having an annual monsoon season?\n",
            "================================================================================\n",
            "\n",
            "--- RANK 1 ---\n",
            "Document: Mali\n",
            "Paragraph Index: 10\n",
            "\n",
            "Paragraph Text:\n",
            "Mali lies in the torrid zone and is among the hottest countries in the world.\n",
            "The thermal equator, which matches the hottest spots year-round on the planet\n",
            "based on the mean daily annual temperature, crosses the country. Most of Mali\n",
            "receives negligible rainfall and droughts are very frequent. Late June to early\n",
            "December is the rainy season in the southernmost area. During this time,\n",
            "flooding of the Niger River is common, creating the Inner Niger Delta. The vast\n",
            "northern desert part of Mali has a hot desert climate (Köppen climate\n",
            "classification (BWh) with long, extremely hot summers and scarce rainfall which\n",
            "decreases northwards. The central area has a hot semi-arid climate (Köppen\n",
            "climate classification (BSh) with very high temperatures year-round, a long,\n",
            "intense dry season and a brief, irregular rainy season. The little southern band\n",
            "possesses a tropical wet and dry climate (Köppen climate classification (Aw)\n",
            "very high temperatures year-round with a dry season and a rainy season.\n",
            "\n",
            "\n",
            "--- RANK 2 ---\n",
            "Document: San_Diego\n",
            "Paragraph Index: 16\n",
            "\n",
            "Paragraph Text:\n",
            "San Diego is one of the top-ten best climates in the Farmers' Almanac and is one\n",
            "of the two best summer climates in America as scored by The Weather Channel.\n",
            "Under the Köppen–Geiger climate classification system, the San Diego area has\n",
            "been variously categorized as having either a semi-arid climate (BSh in the\n",
            "original classification and BSkn in modified Köppen classification) or a\n",
            "Mediterranean climate (Csa and Csb). San Diego's climate is characterized by\n",
            "warm, dry summers and mild winters with most of the annual precipitation falling\n",
            "between December and March. The city has a mild climate year-round, with an\n",
            "average of 201 days above 70 °F (21 °C) and low rainfall (9–13 inches [230–330\n",
            "mm] annually). Dewpoints in the summer months range from 57.0 °F (13.9 °C) to\n",
            "62.4 °F (16.9 °C).\n",
            "\n",
            "\n",
            "--- RANK 3 ---\n",
            "Document: Alaska\n",
            "Paragraph Index: 8\n",
            "\n",
            "Paragraph Text:\n",
            "The climate in Southeast Alaska is a mid-latitude oceanic climate (Köppen\n",
            "climate classification: Cfb) in the southern sections and a subarctic oceanic\n",
            "climate (Köppen Cfc) in the northern parts. On an annual basis, Southeast is\n",
            "both the wettest and warmest part of Alaska with milder temperatures in the\n",
            "winter and high precipitation throughout the year. Juneau averages over 50 in\n",
            "(130 cm) of precipitation a year, and Ketchikan averages over 150 in (380 cm).\n",
            "This is also the only region in Alaska in which the average daytime high\n",
            "temperature is above freezing during the winter months.\n",
            "\n",
            "\n",
            "--- RANK 4 ---\n",
            "Document: Portugal\n",
            "Paragraph Index: 29\n",
            "\n",
            "Paragraph Text:\n",
            "Portugal is defined as a Mediterranean climate (Csa in the South, interior, and\n",
            "Douro region; Csb in the North, Central Portugal and coastal Alentejo; mixed\n",
            "oceanic climate along the northern half of the coastline and also Semi-arid\n",
            "climate or Steppe climate (BSk in certain parts of Beja district far South)\n",
            "according to the Köppen-Geiger Climate Classification), and is one of the\n",
            "warmest European countries: the annual average temperature in mainland Portugal\n",
            "varies from 8–12 °C (46.4–53.6 °F) in the mountainous interior north to 16–19 °C\n",
            "(60.8–66.2 °F) in the south and on the Guadiana river basin. The Algarve,\n",
            "separated from the Alentejo region by mountains reaching up to 900 metres (3,000\n",
            "ft) in Alto de Fóia, has a climate similar to that of the southern coastal areas\n",
            "of Spain or Southwest Australia.\n",
            "\n",
            "\n",
            "--- RANK 5 ---\n",
            "Document: Southeast_Asia\n",
            "Paragraph Index: 9\n",
            "\n",
            "Paragraph Text:\n",
            "The climate in Southeast Asia is mainly tropical–hot and humid all year round\n",
            "with plentiful rainfall. Northern Vietnam and the Myanmar Himalayas are the only\n",
            "regions in Southeast Asia that feature a subtropical climate, which has a cold\n",
            "winter with snow. The majority of Southeast Asia has a wet and dry season caused\n",
            "by seasonal shift in winds or monsoon. The tropical rain belt causes additional\n",
            "rainfall during the monsoon season. The rain forest is the second largest on\n",
            "earth (with the Amazon being the largest). An exception to this type of climate\n",
            "and vegetation is the mountain areas in the northern region, where high\n",
            "altitudes lead to milder temperatures and drier landscape. Other parts fall out\n",
            "of this climate because they are desert like.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Review the first 5 questions and their matched paragraphs\n",
        "import textwrap\n",
        "\n",
        "# Get first question\n",
        "first_5_questions = df_ques_vec.sort_values('question_id').head(5)\n",
        "\n",
        "for q_idx in range(5):\n",
        "    question_id = first_5_questions['question_id'].iloc[q_idx]\n",
        "    question_text = df_questions[df_questions['question_id'] == question_id]['question'].iloc[0]\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(f\"QUESTION ID: {question_id}\")\n",
        "    print(f\"Question: {question_text}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Find the matches for this question in our matches dataframe\n",
        "    question_matches = df_matches[df_matches['question_id'] == question_id].sort_values('question_rank')\n",
        "    \n",
        "    for _, match in question_matches.iterrows():\n",
        "        rank = match['question_rank']\n",
        "        doc_title = match['document_title']\n",
        "        para_idx = match['paragraph_index']\n",
        "        \n",
        "        # Get the actual paragraph text\n",
        "        paragraph = df[(df['document_title'] == doc_title) & \n",
        "                      (df['paragraph_index'] == para_idx)]['paragraph_context'].iloc[0]\n",
        "        \n",
        "        print(f\"\\n--- RANK {rank + 1} ---\")\n",
        "        print(f\"Document: {doc_title}\")\n",
        "        print(f\"Paragraph Index: {para_idx}\")\n",
        "        print(f\"\\nParagraph Text:\")\n",
        "        # Wrap text to 80 characters for readability\n",
        "        wrapped_text = textwrap.fill(paragraph, width=80)\n",
        "        print(wrapped_text)\n",
        "        print()\n",
        "    \n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FqfB5lZ087m"
      },
      "source": [
        "Submit \"worst-paragraphs.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHaFK8Z10xnS"
      },
      "source": [
        "Write a file \"worst-paragraphs.tsv\" with three columns question_id, document_title, paragraph_index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "worst-paragraphs.tsv file created\n"
          ]
        }
      ],
      "source": [
        "# create worst paragraphs dataframe\n",
        "question_ids = [1, 4, 7, 10, 13]\n",
        "worst_paragraph_idx = [9, 5, 12, 50, 9]\n",
        "document_titles = ['Rajasthan', 'classical_music', 'Gymnastics', 'Computer', 'Southeast_Asia']\n",
        "\n",
        "df_worst = pd.DataFrame({'question_id': question_ids, 'document_title': document_titles, 'paragraph_index': worst_paragraph_idx})\n",
        "df_worst.to_csv('submission/worst-paragraph.tsv', sep='\\t', index=False)\n",
        "print(\"worst-paragraphs.tsv file created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 7: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 8: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
